{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Layers\n",
    "\n",
    "We Implement a self-attention layer from scratch using PyTorch. \n",
    "Additionally, we construct a classification model consisting of one self-attention layer followed by a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        #query matrix, key matrix, value matrix Q, K, V\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim) \n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        #https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "    def forward(self, x):\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "        K_T = K.transpose(-1, -2) #note to self, torch.t and torch.transpose are not the same, also need to specify dims\n",
    "        Q_K_T= torch.bmm(Q, K_T) #for pytorch bmm performs \"batch matrix-matrix product of matrices\"\n",
    "        #d is normalization scaling\n",
    "        d= self.input_dim\n",
    "        M_cap= Q_K_T/math.sqrt(d)\n",
    "        #ATT: Rl1×dk × Rl2×dk × Rl2×dv → Rl1×dv from the slides\n",
    "        M = self.softmax(M_cap)\n",
    "        return M_cap, V\n",
    "class Fully_Connected_Layer(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Fully_Connected_Layer, self).__init__()\n",
    "        self.fc_layer = nn.Linear(input_dim, input_dim)\n",
    "    def forward(self, x):\n",
    "        return self.fc_layer(x)\n",
    "    \n",
    "class Joint_Layers(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Joint_Layers, self).__init__()\n",
    "        self.self_attention = SelfAttention(input_dim)\n",
    "        self.fc_layer = Fully_Connected_Layer(input_dim)\n",
    "    def forward(self, X, Y):\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
    "        attention_weights, values = self.self_attention(X_tensor)\n",
    "        predictions = self.fc_layer(values)\n",
    "        return predictions, attention_weights, Y_tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def split_and_convert_to_tensors(X, Y, train_size=0.8, test_size=0.2):\n",
    "    np.random.seed(1)\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    X, Y = X[indices], Y[indices]\n",
    "    n_train = int(len(X) * train_size)\n",
    "    X_train, Y_train = X[:n_train], Y[:n_train]\n",
    "    X_test, Y_test = X[n_train:], Y[n_train:]\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)#only to X i need a \"sequence\"\n",
    "    Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)#only to X i need a \"sequence\"\n",
    "    Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "    return X_train_tensor, Y_train_tensor, X_test_tensor, Y_test_tensor\n",
    "\n",
    "\n",
    "def visualization(attention_weights):\n",
    "    attention_weights = attention_weights.squeeze().detach().numpy()\n",
    "    attention_weights = attention_weights.reshape(1, -1)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(attention_weights)\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.title(\"Weights\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_and_test_model(X_train_tensor, Y_train_tensor, X_test_tensor, Y_test_tensor, input_dim, epochs, batch_size=16, miu=0.01):\n",
    "    model = Joint_Layers(input_dim)\n",
    "    loss_criteria = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), miu)\n",
    "    train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss =0.0\n",
    "        for X_batch, Y_batch in train_loader:\n",
    "            predictions, _, _ = model(X_batch, Y_batch)\n",
    "            predictions = predictions.squeeze(1)\n",
    "            Y_batch = Y_batch.long()\n",
    "            loss = loss_criteria(predictions, Y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(\"Epoch\", epoch+1, \"/\", epochs, \", Loss: \", epoch_loss)\n",
    "    model.eval()\n",
    "    with torch.no_grad(): #to run without affecting, testing\n",
    "        predictions, attention_weights, _ = model(X_test_tensor, Y_test_tensor)\n",
    "        predictions = predictions.squeeze(1)\n",
    "        Y_test_tensor = Y_test_tensor.long()\n",
    "        _, predicted_classes = torch.max(predictions, 1)\n",
    "        correct = (predicted_classes == Y_test_tensor).sum().item()\n",
    "        accuracy = correct / Y_test_tensor.size(0)\n",
    "        print(\"Test Accuracy:  \",accuracy)\n",
    "        #print(attention_weights.squeeze().detach().numpy())\n",
    "        visualization(attention_weights)\n",
    "\n",
    "    return model, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\AppData\\Local\\Temp\\ipykernel_20712\\2281854918.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "C:\\Users\\josep\\AppData\\Local\\Temp\\ipykernel_20712\\2281854918.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_tensor = torch.tensor(Y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 20 , Loss:  12.00667154788971\n",
      "Epoch 2 / 20 , Loss:  9.135329127311707\n",
      "Epoch 3 / 20 , Loss:  7.2891581654548645\n",
      "Epoch 4 / 20 , Loss:  5.897262334823608\n",
      "Epoch 5 / 20 , Loss:  4.774075031280518\n",
      "Epoch 6 / 20 , Loss:  4.013842523097992\n",
      "Epoch 7 / 20 , Loss:  3.5463463068008423\n",
      "Epoch 8 / 20 , Loss:  3.0230879485607147\n",
      "Epoch 9 / 20 , Loss:  2.735535904765129\n",
      "Epoch 10 / 20 , Loss:  2.554648593068123\n",
      "Epoch 11 / 20 , Loss:  2.380050629377365\n",
      "Epoch 12 / 20 , Loss:  2.2714468389749527\n",
      "Epoch 13 / 20 , Loss:  2.0419142693281174\n",
      "Epoch 14 / 20 , Loss:  1.9674778431653976\n",
      "Epoch 15 / 20 , Loss:  1.8301585242152214\n",
      "Epoch 16 / 20 , Loss:  1.7056546434760094\n",
      "Epoch 17 / 20 , Loss:  1.638943076133728\n",
      "Epoch 18 / 20 , Loss:  1.5847541689872742\n",
      "Epoch 19 / 20 , Loss:  1.456699088215828\n",
      "Epoch 20 / 20 , Loss:  1.3705769255757332\n",
      "Test Accuracy:   0.9333333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Testing Accuracy:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "iris_data = pd.read_csv(\"iris.data\", delimiter=\",\", header=None)\n",
    "\n",
    "\n",
    "labels = np.unique(iris_data.iloc[:,-1])\n",
    "labels_coded = dict(zip(labels, range(1, len(labels) + 1)))\n",
    "iris_data.iloc[:,-1] = iris_data.iloc[:,-1].map(labels_coded)\n",
    "Y=iris_data.iloc[:, -1]\n",
    "X = iris_data.drop(iris_data.columns[-1], axis=1)\n",
    "\n",
    "\n",
    "def scale(x,mean, std):\n",
    "    z= (x-mean)/std\n",
    "    return z\n",
    "for xn in X.columns:\n",
    "    mean, std= X[xn].mean(), X[xn].std()\n",
    "    X[xn] = scale(X[xn], mean, std)\n",
    "\n",
    "\n",
    "X = X.to_numpy()\n",
    "Y = Y.to_numpy()\n",
    "Y = Y.astype(np.int64)\n",
    "\n",
    "#input_dim = X.shape[1] \n",
    "#model = Joint_Layers(input_dim)\n",
    "#predictions, attention_weights, Y_tensor = model(X, Y)\n",
    "\n",
    "X_train_tensor, Y_train_tensor, X_test_tensor, Y_test_tensor = split_and_convert_to_tensors(X, Y)\n",
    "input_dim = X_train_tensor.shape[2]\n",
    "trained_model, test_accuracy = train_and_test_model(X_train_tensor, Y_train_tensor, X_test_tensor, Y_test_tensor, input_dim, 20)\n",
    "\n",
    "print(\"Final Testing Accuracy: \",test_accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer-Based Text Generator from scratch using PyTorch\n",
    "It includes:\n",
    "• An embedding layer for input tokens\n",
    "• Positional encoding\n",
    "• Multi-head self-attention (with a causal mask to prevent attending to future tokens)\n",
    "• Feed-forward layers\n",
    "• Residual connections and layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#processing the text\n",
    "#load, make lower case, find out how much to pad, pad, find unique words and convert my array into a tensor so i can use pytorch\n",
    "HP_df = pd.read_csv(\"Harry_Potter_all_books_preprocessed.txt\", sep=r'[.!?]', header=None, engine='python')\n",
    "HP_df = HP_df.T\n",
    "HP_df = HP_df.iloc[:50000]\n",
    "\n",
    "HP_array = np.array(HP_df)\n",
    "HP_array = HP_array.astype(str)\n",
    "HP_array = np.char.lower(HP_array) #make lower case\n",
    "sentences = HP_array.flatten()\n",
    "\n",
    "max_length= 20 #attempt at optimizing time, max 20 words per sentence\n",
    "\n",
    "split_sentences = [word.split()[:max_length] for word in sentences]\n",
    "max_length = max(len(sentence) for sentence in split_sentences)\n",
    "if max_length % 2 != 0:\n",
    "    max_length += 1 #i make it an even number, it gives me trouble down the road\n",
    "\n",
    "\n",
    "\n",
    "HP_array_padded = np.array([sentence + [''] * (max_length - len(sentence)) for sentence in split_sentences]) #multiply by a \"padding distance\"\n",
    "unique_words_array = np.unique(HP_array_padded)\n",
    "\n",
    "#will get dictionary for converting, but based on future parts also need a reversed one to \"de-translate\"\n",
    "\n",
    "dictionary = {word: id_number for id_number, word in enumerate(unique_words_array)}\n",
    "dictionary[''] = 0\n",
    "\n",
    "coded_array = np.vectorize(lambda word: dictionary[word])(HP_array_padded)\n",
    "coded_tensor = torch.tensor(coded_array, dtype=torch.long)\n",
    "\n",
    "vocab_size = len(dictionary)\n",
    "reverse_dictionary = {id_num: word_ for word_, id_num in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the Classes to build the model\n",
    "#when we embed we describe each word in m amount of dimensiones, that will take as embedding_dim\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, word_range, embedding_dim):\n",
    "        #in pytorch nn we need a super to initialze\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embedding = nn.Embedding(word_range, embedding_dim, padding_idx=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "#for positional encoding we will take the max lenght of the sequence allowed\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        #first we use this parameters for an empty matriz with zeroes\n",
    "        self.encoding = torch.zeros(max_length, embedding_dim)\n",
    "        #this uses the sin and cosine formulas from the article \"Attention is all you need\", page 6\n",
    "        position = torch.arange(0, max_length).unsqueeze(1)\n",
    "        denominator = torch.exp(torch.arange(0, embedding_dim, 2) * -(np.log(10000.0) / embedding_dim))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * denominator)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * denominator)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.encoding[:, :x.size(1), :]\n",
    "\n",
    "class MHA_FF_layers(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, hidden_dim):\n",
    "        super(MHA_FF_layers, self).__init__()\n",
    "        # there is a PyTorch MHA so will use that one\n",
    "        # from documentation attn_mask (Optional[Tensor]) – If specified, a 2D or 3D mask preventing attention to certain positions\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "        # we normalize with a PyTorch function\n",
    "        self.norm1 = nn.LayerNorm(embedding_dim)\n",
    "        # next we just apply a ff, a sequential like we have done in other exercises\n",
    "        self.ff = nn.Sequential(nn.Linear(embedding_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, embedding_dim))\n",
    "        # we normalize\n",
    "        self.norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        # we pass the values through our whole block\n",
    "        attn_output, _ = self.attention(x, x, x, attn_mask=attn_mask)\n",
    "        x = self.norm1(x + attn_output)\n",
    "        ff_output = self.ff(x)\n",
    "        x = self.norm2(x + ff_output)\n",
    "        return x\n",
    "\n",
    "# now we try to run the model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_words, embedding_dim, max_length, num_heads, hidden_dim, num_layers):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        # we embed and positionally encode as the first two layers\n",
    "        self.embedding_layer = EmbeddingLayer(num_words, embedding_dim)\n",
    "        self.positional_encoding_layer = PositionalEncoding(embedding_dim, max_length)\n",
    "        self.mha_ff_layer_sequence = nn.ModuleList([MHA_FF_layers(embedding_dim, num_heads, hidden_dim) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Linear(embedding_dim, num_words)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.positional_encoding_layer(x)\n",
    "        # we create a triangular matrix of ones for the mask\n",
    "        ones_torch = torch.ones(x.size(1), x.size(1))\n",
    "        mask_to_use = torch.tril(ones_torch)\n",
    "        for layer in self.mha_ff_layer_sequence:\n",
    "            x = layer(x, attn_mask=mask_to_use)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters and training\n",
    "embedding_dimensions = 100\n",
    "num_heads = 20\n",
    "hidden_dim = 400\n",
    "num_layers = 6\n",
    "number_of_words = len(dictionary)\n",
    "max_length = max_length\n",
    "\n",
    "model = TransformerModel(number_of_words, embedding_dimensions, max_length, num_heads, hidden_dim, num_layers)\n",
    "loss_criteria = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #increasing learning rate has very bad effects in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Loss: 5.4641\n",
      "Epoch 2/7, Loss: 2.1569\n",
      "Epoch 3/7, Loss: 0.4230\n",
      "Epoch 4/7, Loss: 0.2100\n",
      "Epoch 5/7, Loss: 0.1464\n",
      "Epoch 6/7, Loss: 0.1230\n",
      "Epoch 7/7, Loss: 0.1200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_model(model, coded_tensor, epochs=7, batch_size=30): #i try different batch sizes since it runs very slowly\n",
    "    dataset = torch.utils.data.TensorDataset(coded_tensor[:, :-1], coded_tensor[:, 1:])\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for input_seq, target_seq in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_seq)\n",
    "            output = output.view(-1, vocab_size)\n",
    "            target_seq = target_seq.view(-1)\n",
    "            loss = loss_criteria(output, target_seq)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "def predict_next_word(model, input_seq):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_seq.unsqueeze(0))\n",
    "        predicted_idx = torch.argmax(output[0, -1]).item()\n",
    "        return reverse_dictionary[predicted_idx]\n",
    "\n",
    "train_model(model, coded_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  the day of the\n",
      "Predicted Words: the same balls of the other that the goblet of\n"
     ]
    }
   ],
   "source": [
    "#to add a custom input i need to split it first and turn it into a usable array\n",
    "def prepare_input(sentence, dictionary, max_length):\n",
    "    words_to_use = sentence.lower().split() #my dictionary is only lower case so we got to adjust so\n",
    "    word_index_from_dictionary = [dictionary.get(word, 0) for word in words_to_use]\n",
    "    if len(word_index_from_dictionary) < max_length:\n",
    "        word_index_from_dictionary += [0] * (max_length - len(word_index_from_dictionary)) #adjust to padding\n",
    "    else:\n",
    "        word_index_from_dictionary = word_index_from_dictionary[:max_length]\n",
    "    return torch.tensor(word_index_from_dictionary, dtype=torch.long)\n",
    "\n",
    "def generate_text(model, input_sentence, dictionary, reverse_dictionary, num_words):\n",
    "    model.eval()\n",
    "    generated_words = []\n",
    "    with torch.no_grad(): #so that i dont affect the model\n",
    "        for _ in range(num_words):\n",
    "            output = model(input_sentence.unsqueeze(0))\n",
    "            predicted_ids = torch.argmax(output[0, -1]).item()  # iteratively predict the next word based on the previous\n",
    "            generated_words.append(reverse_dictionary.get(predicted_ids, \" \"))\n",
    "            #update the input sentence with the predicted word\n",
    "            input_sentence = torch.cat((input_sentence[1:], torch.tensor([predicted_ids], dtype=torch.long)))\n",
    "    return generated_words\n",
    "\n",
    "#here in sentence you would add your custom prompt\n",
    "sentence = \"the day of the\"\n",
    "input_prompt = prepare_input(sentence, dictionary, max_length)\n",
    "next_words = generate_text(model, input_prompt, dictionary, reverse_dictionary, num_words=10)\n",
    "\n",
    "print(\"Prompt: \", sentence)\n",
    "print(\"Predicted Words:\", ' '.join(next_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
